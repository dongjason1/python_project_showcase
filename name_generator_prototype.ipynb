{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15+"
    },
    "colab": {
      "name": "name_generator_prototype1 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHesavvhPhCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "44b46a39-a7e7-4c72-d26a-346f40e5a4f4"
      },
      "source": [
        "import sys, os, json, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "uasg5T4PPhCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#company names\n",
        "#dataset = pd.read_csv('https://raw.githubusercontent.com/EliotAndres/char-rnn-tensorflow-js/master/python/companies.csv', header=None)\n",
        "#dataset = set(str(v) for v in dataset.to_numpy().squeeze())\n",
        "\n",
        "# baby names\n",
        "#dataset = pd.read_csv('https://raw.githubusercontent.com/dongjason1/python_project_showcase/master/data/NationalNames.csv')\n",
        "#dataset = set(str(v) for v in dataset[[1]].to_numpy().squeeze())\n",
        "\n",
        "# college names\n",
        "# dataset = pd.read_csv('https://raw.githubusercontent.com/dongjason1/python_project_showcase/master/data/College.csv')\n",
        "# dataset = set(str(v) for v in dataset[['Unnamed: 0']].to_numpy().squeeze())\n",
        "\n",
        "# benedict cumberbatch \n",
        "# future work: https://the-toast.net/2013/12/02/a-linguist-explains-the-rules-of-summoning-benedict-cumberbatch/\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/dongjason1/python_project_showcase/master/data/benedict_cumberbatch.csv', header=None)\n",
        "dataset = set(str(v) for v in dataset.to_numpy().squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulUBTdBMPhCj",
        "colab_type": "code",
        "outputId": "fc2d2aab-abf8-423d-a34c-0e3f09957477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "training_data = '\\n'.join(dataset)\n",
        "# Get chars and map to int\n",
        "chars = sorted(list(set(training_data)))\n",
        "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
        "int_to_char = dict((i,c) for i,c in enumerate(chars))\n",
        "print('# Names: {}'.format(len(dataset)))\n",
        "print('Number of Chars in Training Data: {}'.format(len(training_data)))\n",
        "print('Number of Unique Chars: {}'.format(len(chars)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Names: 537\n",
            "Number of Chars in Training Data: 12036\n",
            "Number of Unique Chars: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5SjqwdoPhCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "78f408d9-c90e-4de1-8c24-6555abf84ffc"
      },
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Model Definition\n",
        "hidden_units = 64\n",
        "data_length = 10\n",
        "step = 3\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(data_length, len(chars))))\n",
        "model.add(Dense(units=len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1029 04:15:42.476196 140054744962944 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFEs1EgHPhCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_length = 10\n",
        "step = 3\n",
        "# Split into feature and target\n",
        "inp = []\n",
        "out = []\n",
        "for i in range(0, len(training_data) - data_length, step):\n",
        "    inp.append(training_data[i:i+data_length])\n",
        "    out.append(training_data[i+data_length])\n",
        "\n",
        "# Vectorize\n",
        "x = np.zeros((len(inp), data_length, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(out), len(chars)), dtype=np.bool)\n",
        "for i, sequence in enumerate(inp):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i, t, char_to_int[char]] = 1\n",
        "    y[i, char_to_int[out[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1zfwe3GHPhCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "d3d7b808-f528-414c-bfcc-6bf0b9419c7d"
      },
      "source": [
        "print(\"{}: Number of Documents in Batch: {}\".format(i, len(x)))\n",
        "model.fit(x, y, epochs=2, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1029 04:15:42.948724 140054744962944 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4008: Number of Documents in Batch: 4009\n",
            "Train on 4009 samples\n",
            "Epoch 1/2\n",
            "4009/4009 [==============================] - 3s 674us/sample - loss: 2.5763\n",
            "Epoch 2/2\n",
            "4009/4009 [==============================] - 2s 424us/sample - loss: 1.8385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60dd53ba10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CldlFqTlPhCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gets a random seed\n",
        "def get_seed():\n",
        "    seed = \"\"\n",
        "    for i in range(10):\n",
        "        num = random.randint(0,len(chars))\n",
        "        seed += int_to_char[num]\n",
        "    return seed\n",
        "\n",
        "# Samples index from given distribution and temperature\n",
        "def sample(preds, temp):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temp\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "    \n",
        "# One hot encodes a string\n",
        "def string_to_vec(string):\n",
        "    vec = np.zeros((1, len(string), len(chars)), dtype=np.bool)\n",
        "    for t, char in enumerate(string):\n",
        "        vec[0, t, char_to_int[char]] = 1\n",
        "    return vec\n",
        "\n",
        "# generates a list of names from the model and an initial seed\n",
        "def generate_name(model, seed, num_results=10, temp = 0.7):\n",
        "    generated = []\n",
        "    text = seed\n",
        "    word = seed\n",
        "    while num_results>0:\n",
        "        vec = string_to_vec(text)\n",
        "        preds = model.predict(vec)[0]\n",
        "        predicted = sample(preds, temp)\n",
        "        character = int_to_char[predicted]\n",
        "        text = text[1:] + character\n",
        "        word += character\n",
        "        if character == '\\n':\n",
        "            num_results -=1\n",
        "            try:\n",
        "              generated.append(word[:-1].encode('ascii'))\n",
        "            except:\n",
        "              print(word[:-1])\n",
        "            word = \"\"\n",
        "        \n",
        "    return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZU65VlIPhC3",
        "colab_type": "code",
        "outputId": "816b6972-aa45-4bf9-efba-8915e873ca88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "# Let's see some results\n",
        "result = generate_name(model, get_seed(), 15, 0.5)\n",
        "result"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fbFn�rsvY�t Cucumberbuck\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bendydick Cucumberbatch',\n",
              " 'Bundybink Cumberbuck',\n",
              " 'Benadick Cumberbatch',\n",
              " 'Benadica Cumbenbunk',\n",
              " 'Bundybick Cumbindensn',\n",
              " 'Bendiblick Cucunumber',\n",
              " 'Buncersnatch',\n",
              " 'Bendydick Cumberbunt',\n",
              " 'Bennyeolen Cumbersnatch',\n",
              " 'Bunderbu Cumberbutch',\n",
              " 'Bumberbink Cumsnatch',\n",
              " 'Bendydick Cumberbonch',\n",
              " 'Bendydick Cumberbonch',\n",
              " 'Benedick Cumbersnatch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RQgw_6BPhC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for r in result:\n",
        "  if r in dataset:\n",
        "    print(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KURBjKUcPyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}